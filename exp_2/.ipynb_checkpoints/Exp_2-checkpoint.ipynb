{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e3dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the query sentence\n",
    "query_sentence = \"insan öldürmenin cezası nedir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ed4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gokhan Has\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "from simpletransformers.ner import NERModel\n",
    "from operator import itemgetter\n",
    "from scipy import spatial\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abac02ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filepath):\n",
    "    if os.path.splitext(filepath)[1] != '.csv':\n",
    "        return  # or whatever\n",
    "    seps = [';', '\\t']  # ',' is default\n",
    "    encodings = [None, 'utf-8', 'ISO-8859-1', 'utf-16', 'ascii']  # None is default\n",
    "    for sep in seps:\n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                return pd.read_csv(filepath, encoding=encoding, sep=sep)\n",
    "            except Exception:  # should really be more specific\n",
    "                pass\n",
    "    raise ValueError(\"{!r} is has no encoding in {} or seperator in {}\"\n",
    "                     .format(filepath, encodings, seps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a94b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install NER model\n",
    "model_NER = NERModel('bert', '../ner_model/', use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c5967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset and initialize dataset values ...\n",
    "df = read_csv('../datasets/exp2_dataset.csv')\n",
    "\n",
    "all_sentences = []\n",
    "oldVal = 0\n",
    "newVal = 1\n",
    "for index in range(0, len(df)):\n",
    "    newVal = df['SENTENCE_ID'][index]\n",
    "    if not oldVal == newVal:\n",
    "        all_sentences.append( {'index': df['SENTENCE_ID'][index], 'sentence': df['SENTENCE'][index]})\n",
    "        oldVal = newVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6e9f14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0078d4dfb06456ea43f3ee7144e29dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc256de627443589947be7ab675625e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Prediction', max=1.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[{'insan': 'B-ELEMENT_OF_CRIME'}, {'öldürmenin': 'I-ELEMENT_OF_CRIME'}, {'cezası': 'I-PUNISHMENT'}, {'nedir': 'O'}]\n"
     ]
    }
   ],
   "source": [
    "# Get the query sentence list\n",
    "query_sentence_list = query_sentence.split(' ')\n",
    "\n",
    "# Get the query sentence named entities\n",
    "prediction, model_output = model_NER.predict([query_sentence])\n",
    "prediction = prediction[0]\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "o_element_list = []\n",
    "ner_query_list = []\n",
    "for index, tup in enumerate(prediction):\n",
    "    if not tup[query_sentence_list[index]] == 'O':\n",
    "        ner_query_list.append(tup)\n",
    "    else:\n",
    "        o_element_list.append(query_sentence_list[index])\n",
    "        \n",
    "prediction = ner_query_list\n",
    "\n",
    "#for i in range(0, len(o_element_list)):\n",
    "#    query_sentence_list.remove(o_element_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0104c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insan', 'öldürmenin', 'cezası', 'nedir']\n",
      "insan\n",
      "öldürmenin\n",
      "cezası\n"
     ]
    }
   ],
   "source": [
    "# Get the query sentence's word's embedding by using ../ner_model. \n",
    "query_word_embeddings_list = []\n",
    "\n",
    "words = []\n",
    "new_sentences = []\n",
    "print(query_sentence_list)\n",
    "for query_index, query_word in enumerate(query_sentence_list):\n",
    "    if not query_word in o_element_list:\n",
    "        print(query_word)\n",
    "        query_word_embeddings = model_output[0][query_index][query_word][0]\n",
    "        query_word_embeddings_list.append(query_word_embeddings)\n",
    "    \n",
    "# print(query_word_embeddings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef7005ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'sentence': 'uyuşturucu veya uyarıcı madde verilen veya satılan kişinin çocuk olması halinde , veren veya satan kişiye verilecek hapis cezası on beş yıldan az olamaz .', 'distance': 0.8542695787211273}\n",
      "\n",
      "\n",
      "2 {'sentence': 'istismarın sarkıntılık düzeyinde kalması halinde üç yıldan sekiz yıla kadar hapis cezasına hükmolunur .', 'distance': 0.8485863087272166}\n",
      "\n",
      "\n",
      "3 {'sentence': 'istismarın vücuda organ veya sair bir cisim sokulması suretiyle gerçekleştirilmesi durumunda , on altı yıldan aşağı olmamak üzere hapis cezasına hükmolunur .', 'distance': 0.8485863087272166}\n",
      "\n",
      "\n",
      "4 {'sentence': 'davranışın sarkıntılık düzeyinde kalması halinde iki yıldan beş yıla kadar hapis cezası verilir .', 'distance': 0.8480413512669612}\n",
      "\n",
      "\n",
      "5 {'sentence': 'sırasında kamunun endişe ve heyecan duymasına neden olacak veya halkın maneviyatını sarsacak veya düşman karşısında ülkenin direncini azaltacak şekilde asılsız veya abartılmış veya özel maksada dayalı havadis veya haber yayan veya nakleden veya temel milli yararlara zarar verebilecek herhangi bir faaliyette bulunan kimseye beş yıldan on yıla kadar hapis cezası verilir .', 'distance': 0.8426662962029869}\n",
      "\n",
      "\n",
      "6 {'sentence': 'cinsel yönden taciz şeklinde gerçekleşmesi halinde , on yıldan onbeş yıla kadar hapis cezasına hükmolunur .', 'distance': 0.8411173594048303}\n",
      "\n",
      "\n",
      "7 {'sentence': 'güvenliğine veya iç veya dış siyasal yararlarına ilişkin belge veya vesikaları kısmen veya tamamen yok eden , tahrip eden veya bunlar üzerinde sahtecilik yapan veya geçici de olsa , bunları tahsis olundukları yerden başka bir yerde kullanan , hileyle alan veya çalan kimseye sekiz yıldan oniki yıla kadar hapis cezası verilir .', 'distance': 0.8244669191556248}\n",
      "\n",
      "\n",
      "8 {'sentence': 've şiddet kullanarak Türkiye Cumhuriyeti Hükûmetini ortadan kaldırmaya veya görevlerini yapmasını kısmen veya tamamen engellemeye teşebbüs eden kimseye ağırlaştırılmış müebbet hapis cezası verilir .', 'distance': 0.8242795155225132}\n",
      "\n",
      "\n",
      "9 {'sentence': 'yetkisi elinden alınmış olan ana veya babanın ya da üçüncü derece dahil kan hısmının , onaltı yaşını bitirmemiş bir çocuğu veli , vasi veya bakım ve gözetimi altında bulunan kimsenin yanından cebir veya tehdit kullanmaksızın kaçırması veya alıkoyması halinde , üç aydan bir yıla kadar hapis cezasına hükmolunur .', 'distance': 0.8239870781911091}\n",
      "\n",
      "\n",
      "10 {'sentence': 'askeri yararı gereği girilmesi yasaklanmış olan yerlere , gizlice veya hile ile girenlere iki yıldan beş yıla kadar hapis cezası verilir .', 'distance': 0.8210624410308242}\n",
      "\n",
      "\n",
      "11 {'sentence': 'fiili işlemek için veya işlediği sırada cebir , tehdit veya hile kullanırsa , iki yıldan yedi yıla kadar hapis cezasına hükmolunur .', 'distance': 0.820106871137793}\n",
      "\n",
      "\n",
      "12 {'sentence': 'yaralamanın vücutta kemik kırılmasına veya çıkığına neden olması halinde , yukarıdaki maddeye göre belirlenen ceza , kırık veya çıkığın hayat fonksiyonlarındaki etkisine göre , yarısına kadar artırılır .', 'distance': 0.8184711266274508}\n",
      "\n",
      "\n",
      "13 {'sentence': 'yaralamanın ihmali davranışla işlenmesi halinde , verilecek ceza üçte ikisine kadar indirilebilir .', 'distance': 0.8184711266274508}\n",
      "\n",
      "\n",
      "14 {'sentence': 'hizmetini yapanları firara sevk edecek veya askerlik hizmetine katılacak olanları bu hizmeti yapmaktan vazgeçirecek şekilde teşvik veya telkinde bulunanlara altı aydan iki yıla kadar hapis cezası verilir .', 'distance': 0.8181648756731678}\n",
      "\n",
      "\n",
      "15 {'sentence': ';Silahla , Kişinin kendisini tanınmayacak bir hale koyması suretiyle , imzasız mektupla veya özel işaretlerle , Birden fazla kişi tarafından birlikte , Var olan veya var sayılan suç örgütlerinin oluşturdukları korkutucu güçten yararlanılarak , İşlenmesi halinde , fail hakkında iki yıldan beş yıla kadar hapis cezasına hükmolunur .', 'distance': 0.8151231633808299}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In this cell, compare dataset's named entity's embeddings and query sentence's word's embeddings...\n",
    "\n",
    "for i in range(0, len(o_element_list)):\n",
    "    query_sentence_list.remove(o_element_list[i])\n",
    "\n",
    "\n",
    "results_list = []\n",
    "\n",
    "oldIndex = 1\n",
    "newIndex = 1\n",
    "for k in range(0, len(prediction)):\n",
    "    control_tag = prediction[k][query_sentence_list[k]]\n",
    "    result_list = []\n",
    "    cumle_list = []\n",
    "    dataset_tag = \"\"\n",
    "    for index in range(0, len(df)):\n",
    "        newIndex = df['SENTENCE_ID'][index] \n",
    "        if not (newIndex == oldIndex):\n",
    "            if len(cumle_list) == 0:\n",
    "                result_list.append({'sentence_id' : oldIndex, 'distance': 0.0})\n",
    "            else:\n",
    "                avg = statistics.mean(cumle_list)\n",
    "                result_list.append({'sentence_id' : oldIndex, 'distance': avg})\n",
    "            # result_list.append(cumle_list)\n",
    "            cumle_list = []\n",
    "            oldIndex = newIndex\n",
    "            \n",
    "        dataset_tag = (df['TAG'][index])[2:len(df['TAG'][index])]\n",
    "        # print(newIndex, df['WORD'][index], dataset_tag)\n",
    "        if dataset_tag == control_tag[2:len(control_tag)]:\n",
    "            # convert list string to list\n",
    "            veriset_emb = ast.literal_eval(df['EMBEDDING'][index])\n",
    "            # find cosine distance between query word and dataset word tag\n",
    "            distances = 1 - spatial.distance.cosine(veriset_emb, query_word_embeddings_list[k])\n",
    "            #cumle_list.append({dataset_tag : distances, 'sentence_id': df['SENTENCE_ID'][index]})\n",
    "            cumle_list.append(distances)\n",
    "   \n",
    "    oldIndex = 1  \n",
    "    results_list.append(result_list)\n",
    "        \n",
    "\n",
    "end_results_list = []\n",
    "\n",
    "for i in range(0, len(results_list)):\n",
    "    newlist = sorted(results_list[i], key=itemgetter('sentence_id'))\n",
    "    end_results_list.append(newlist)\n",
    "\n",
    "\n",
    "if not len(end_results_list) == 0:\n",
    "    similarity_value_list = [0] * len(end_results_list[0])\n",
    "    size = len(prediction)\n",
    "\n",
    "    for i, list_dict in enumerate(end_results_list):\n",
    "        for index, one_dict in enumerate(list_dict):   \n",
    "            dict_values = list(one_dict.values())\n",
    "            similarity_value_list[index] = similarity_value_list[index] + dict_values[1]\n",
    "\n",
    "    similarity_value_list = [number / size for number in similarity_value_list]\n",
    "    #print(similarity_value_list)\n",
    "\n",
    "\n",
    "    results_dict = []\n",
    "    for i, list_dict in enumerate(end_results_list):\n",
    "        for index, one_dict in enumerate(list_dict):\n",
    "            dict_values = list(one_dict.values())\n",
    "            results_dict.append({'sentence_id': dict_values[0], 'distance': similarity_value_list[index]})\n",
    "        break\n",
    "\n",
    "    #print(results_dict)\n",
    "\n",
    "\n",
    "    results_dict_2 = sorted(results_dict, key=lambda x: float(x['distance']), reverse=True)    \n",
    "    result_10 = results_dict_2[:10]\n",
    "\n",
    "\n",
    "    son = []\n",
    "    for i, _dict in enumerate(result_10):\n",
    "        for index, val in enumerate(all_sentences):\n",
    "            if val['index'] == _dict['sentence_id']:\n",
    "                son.append({'sentence' : val['sentence'], 'distance': _dict['distance']})\n",
    "\n",
    "    for i, val in enumerate(son):\n",
    "        print(i+1, val)\n",
    "        print(\"\\n\")\n",
    "else:\n",
    "    print('!!! NO ENTITY !!! CANNOT COMPARE !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d23417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8943fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
